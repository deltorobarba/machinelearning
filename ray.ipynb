{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp4b4hTD72QDWGMAkR+gwz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/machinelearning/blob/main/ray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# PyTorch on Ray on Vertex AI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/ray_on_vertex_ai/get_started_with_pytorch_rov.ipynb"
      ],
      "metadata": {
        "id": "D8PxqPKLgBfH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24743cf4a1e1"
      },
      "source": [
        "**_NOTE_**: This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.9"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/google-cloud/ray-got-new-friends-orchestrating-ray-based-ml-pipeline-on-vertex-ai-5f243eaf2947\n",
        "\n",
        "* As you use vertex ai pipelines to distribute training with tensorflow  and torch\n",
        "* You can adopt ray as unique framework to distribute training (and more)\n",
        "* But it will always be a component in the overall ML workflow (e.g. with kubeflow)\n",
        "* also we are working on ray serverless in colab with dataproc team\n",
        "* so it is going to be sooooo easy to orchestrate ray on vertex ai\n"
      ],
      "metadata": {
        "id": "t7Ak1W37ZiU6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This tutorial demonstrates how to use Ray on Vertex AI SDK and Vertex AI SDK for training and serving an PyTorch image classification model.\n",
        "\n",
        "Learn more about [Ray on Vertex AI overview](https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how to efficiently distribute the training process of a PyTorch image classification model by leveraging Ray on Vertex AI. Furthermore, you learn how to deploy the trained model seamlessly to Vertex AI Endpoint.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services and resources:\n",
        "\n",
        "- Ray on Vertex AI\n",
        "- Vertex AI Model Registry\n",
        "- Vertex AI Prediction\n",
        "\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Prepare the training script\n",
        "- Submit a Ray job using the Ray Jobs API\n",
        "- Download a trained image model from PyTorch\n",
        "- Create a custom model handler\n",
        "- Package model artifacts in a model archive file\n",
        "- Register model in Vertex AI Model Registry\n",
        "- Deploy model in Vertex AI Endpoint\n",
        "- Make online predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08d289fa873f"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "This tutorial uses the [CIFAR-10 dataset](https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html) which consists of 60000 32x32 colour images in 10 classes, with 6000 images per class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
        "and [Cloud Storage pricing](https://cloud.google.com/storage/pricing),\n",
        "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/ai-machine-learning/ray-on-vertex-ai"
      ],
      "metadata": {
        "id": "-x9OYPXFJQu9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1ea81ac77f0"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5d353aa47ac"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "462b9c16e32b"
      },
      "outputs": [],
      "source": [
        "! pip3 install google-cloud-aiplatform[ray]==1.56.0 ray[data,train,tune,serve] google-cloud-bigquery-storage pyarrow gcsfs setuptools==69.5.1 \"numpy<2\" -q --no-warn-conflicts\n",
        "! pip3 install torch==2.1.2 torchvision==0.16.2 torchmetrics==1.2.1 torchserve==0.9.0 torch-model-archiver==0.9.0 -q --no-warn-conflicts\n",
        "! pip3 install google-auth==2.27.0 etils==1.5.2 -q --no-warn-conflicts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16220914acc5"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "157953ab28f0"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c87a2a5d7e35"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dccb1c8feb6"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc7251520a07"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2fc3d7b6bfa"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK for Python\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f02130bff721"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"lunar-352813\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = \"gs://energy-lunar-352813-001\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**If your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIq7R4HZCfIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c5c921-b78b-4898-fecb-621f44878f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://energy-lunar-352813-001/...\n"
          ]
        }
      ],
      "source": [
        "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d5191a94246"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de483dc2a7ee"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform as vertex_ai\n",
        "\n",
        "vertex_ai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "454cb4f7a9e9"
      },
      "source": [
        "#### Timestamp\n",
        "\n",
        "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, create a timestamp for each instance session, and append the timestamp onto the name of resources you create in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8c17026c384"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObZfmnat7BaA"
      },
      "source": [
        "### Add torch-model-archiver to the PATH\n",
        "\n",
        "Update the `PATH` environment variable to add `torch-model-archiver`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRRsfkBu7C8M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PATH\"] = f'{os.environ.get(\"PATH\")}:~/.local/bin'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9ryiScCEapt"
      },
      "source": [
        "### Set a Ray cluster on Vertex AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwmK5nBBCgJa"
      },
      "source": [
        "Before running the code below, make sure to [set up](https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/set-up) Ray on Vertex AI and [create](https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/create-cluster) at least one Ray cluster on Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mlq_1NLEonF"
      },
      "outputs": [],
      "source": [
        "import vertex_ray\n",
        "from vertex_ray import Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15PYjIyOcx1d"
      },
      "source": [
        "#### Define cluster configuration\n",
        "\n",
        "To provision a Ray cluster on Vertex AI, you can use a default provisioning request or you can specify the replica count (number of nodes), machine type, disk_spec, and accelerator as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjLG3rsRbiHr"
      },
      "outputs": [],
      "source": [
        "head_node_type = Resources(\n",
        "    machine_type=\"n1-standard-16\",\n",
        "    node_count=1,\n",
        ")\n",
        "\n",
        "worker_node_types = [\n",
        "    Resources(\n",
        "        machine_type=\"n1-standard-16\",\n",
        "        node_count=2,\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O1xUMt7Z6r0"
      },
      "source": [
        "#### Create the Ray cluster\n",
        "\n",
        "Create the Ray cluster using the Vertex AI SDK for Python version used with Ray."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The latest image in the Ray cluster includes Ray 2.33\n",
        "# The latest supported Python version is Python 3.10\n",
        "!pip install google-cloud-aiplatform[ray]"
      ],
      "metadata": {
        "id": "JXey7rWTMOB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZkHOH3v2i1p"
      },
      "outputs": [],
      "source": [
        "cluster_name = f\"ray-cluster-{TIMESTAMP}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-g6kLwqUj5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d017042-ee0e-47f1-fa21-744e198d6c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 1; sleeping for 0:02:30 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 2; sleeping for 0:01:54.750000 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 3; sleeping for 0:01:27.783750 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 4; sleeping for 0:01:07.154569 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 5; sleeping for 0:00:51.373245 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 6; sleeping for 0:00:39.300532 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 7; sleeping for 0:00:30.064907 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 8; sleeping for 0:00:30.064907 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 9; sleeping for 0:00:30.064907 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 10; sleeping for 0:00:30.064907 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 11; sleeping for 0:00:30.064907 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 12; sleeping for 0:00:30.064907 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 13; sleeping for 0:00:30.064907 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 14; sleeping for 0:00:30.064907 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 15; sleeping for 0:00:30.064907 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 16; sleeping for 0:00:30.064907 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.PROVISIONING\n",
            "Waiting for cluster provisioning; attempt 17; sleeping for 0:00:30.064907 seconds\n",
            "[Ray on Vertex AI]: Cluster State = State.RUNNING\n"
          ]
        }
      ],
      "source": [
        "ray_cluster_name = vertex_ray.create_ray_cluster(\n",
        "    head_node_type=head_node_type,\n",
        "    worker_node_types=worker_node_types,\n",
        "    cluster_name=cluster_name,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmBlsbHAc2uO"
      },
      "source": [
        "#### Get the Ray cluster\n",
        "\n",
        "Use the Vertex AI SDK for Python to get the Ray cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UzG2WyXbZJi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c6bcd22-e913-4987-b354-4b6f04356239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ray cluster on Vertex AI: projects/892203813305/locations/us-central1/persistentResources/ray-cluster-20240913115231\n"
          ]
        }
      ],
      "source": [
        "ray_cluster = vertex_ray.get_ray_cluster(ray_cluster_name)\n",
        "print(\"Ray cluster on Vertex AI:\", ray_cluster_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek1-iTbPjzdJ"
      },
      "source": [
        "### Set tutorial folder\n",
        "\n",
        "Set up the folder you use in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbfKRabXj3la"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path as path\n",
        "\n",
        "root_path = path.cwd()\n",
        "tutorial_path = root_path / \"tutorial\"\n",
        "src_path = tutorial_path / \"src\"\n",
        "deliverables_path = tutorial_path / \"deliverables\"\n",
        "build_path = tutorial_path / \"build\"\n",
        "tests_path = tutorial_path / \"tests\"\n",
        "\n",
        "src_path.mkdir(parents=True, exist_ok=True)\n",
        "deliverables_path.mkdir(parents=True, exist_ok=True)\n",
        "build_path.mkdir(parents=True, exist_ok=True)\n",
        "tests_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import io\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import string\n",
        "import time\n",
        "\n",
        "# Ray - Training\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "# General\n",
        "from etils import epath\n",
        "from matplotlib import pyplot as plt\n",
        "from ray.job_submission import JobStatus, JobSubmissionClient\n",
        "# Serving\n",
        "from ray.tune import ExperimentAnalysis\n",
        "from vertex_ray.predict import torch as ray_torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFgb-sZbBi8i"
      },
      "source": [
        "### Set variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zykxFjqUB9jt"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "LOGGING_URI = epath.Path(BUCKET_URI) / \"logs\"\n",
        "EXPERIMENT_NAME = \"torch_on_rov\"\n",
        "TRAINING_URI = LOGGING_URI / EXPERIMENT_NAME\n",
        "TRAINING_PATH = deliverables_path / EXPERIMENT_NAME\n",
        "\n",
        "# serving\n",
        "DELIVERABLES_PATH = str(deliverables_path)\n",
        "BUILD_URI = str(epath.Path(BUCKET_URI) / \"build\")\n",
        "DEPLOY_IMAGE_URI = \"us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu.1-11:latest\"\n",
        "MODEL_NAME = \"torch_on_rov_cifar10\"\n",
        "DEPLOY_COMPUTE = \"n1-standard-4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYQNboaOBk6B"
      },
      "source": [
        "### Define helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-bl6h54bqFz"
      },
      "outputs": [],
      "source": [
        "def get_id(k=3):\n",
        "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=k))\n",
        "\n",
        "\n",
        "def plot_image_sample(test_dataset):\n",
        "    \"\"\"Plots a sample image from the CIFAR-10 dataset.\"\"\"\n",
        "\n",
        "    sample_idx = random.randrange(0, len(test_dataset))\n",
        "    image, _ = test_dataset[sample_idx]\n",
        "    pil_image = transforms.ToPILImage()(image)\n",
        "    plt.imshow(pil_image)\n",
        "    plt.show()\n",
        "\n",
        "    return pil_image\n",
        "\n",
        "\n",
        "def predict_from_image(pil_image, endpoint):\n",
        "    \"\"\"Predicts the class of an image using the given endpoint.\"\"\"\n",
        "    buffered_image = io.BytesIO()\n",
        "    pil_image.save(buffered_image, format=\"JPEG\")\n",
        "\n",
        "    data = {\"data\": base64.b64encode(buffered_image.getvalue()).decode(\"utf-8\")}\n",
        "    response = endpoint.predict(instances=[data])\n",
        "\n",
        "    return response.predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BH0TlP3PtTB"
      },
      "source": [
        "## Training a PyTorch model\n",
        "\n",
        "In this tutorial, you train a custom image classification model using Ray on Vertex AI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh2BbfWPXglw"
      },
      "source": [
        "#### Prepare the training application\n",
        "\n",
        "Before you start the training, let's take a look at how a Ray job might be assembled to distribute your training.\n",
        "\n",
        "Ray 2.4.0 uses `train_loop_per_worker` fuction to a distributed multi-worker training function.\n",
        "\n",
        "After you set up your dataset and your model, define your single-worker PyTorch training function and then convert it to distributed multi-worker training function as followed:\n",
        "\n",
        "1. Use the `ray.train.torch.prepare_data_loader` to wrap your data with  `DistributedSampler` for distributed training.\n",
        "\n",
        "2. Use the `ray.train.torch.prepare_model` function to wrap your model with  `DistributedDataParallel` for distributed training.\n",
        "\n",
        "After you have your multi-worker training function, you need to define the `ScalingConfig` to specify the desired number of workers and indicate whether the distributed training process requires GPUs.\n",
        "\n",
        "Additionally, you can define a `RunConfig` to specify checkpointing and synchronization behaviors along the distributed training workload and some additional training loop parameters.\n",
        "\n",
        "Finally, pass everything to `TorchTrainer`, which Ray uses to distribute your training utilizing Distributed Data Parallelism (using PyTorch’s Distributed backend)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pznqJKCpEcL3"
      },
      "source": [
        "### Prepare the training script\n",
        "\n",
        "The file `src/task.py` is the Python script for executing the Ray distributed training job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCFfhM7RP4RI"
      },
      "outputs": [],
      "source": [
        "training_script = \"\"\"\n",
        "# libraries\n",
        "\n",
        "# general libraries\n",
        "import os\n",
        "import argparse\n",
        "from etils import epath\n",
        "import tempfile\n",
        "\n",
        "# training libraries\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torchmetrics.aggregation import MeanMetric\n",
        "from torchmetrics.classification.accuracy import Accuracy\n",
        "\n",
        "# ray libraries\n",
        "import ray\n",
        "from ray import train\n",
        "from ray.train import ScalingConfig, RunConfig, CheckpointConfig, Checkpoint, FailureConfig\n",
        "from ray.train.torch import TorchTrainer, TorchCheckpoint\n",
        "\n",
        "\n",
        "# helpers\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
        "    parser.add_argument('--batch-size', dest='batch_size',\n",
        "                        type=int, default=16, help='Batch size')\n",
        "    parser.add_argument('--epochs', dest='epochs',\n",
        "                        type=int, default=10, help='Number of epochs')\n",
        "    parser.add_argument('--lr', dest='lr',\n",
        "                        type=int, default=1e-3, help='Learning rate')\n",
        "    parser.add_argument('--num-workers', dest='num_workers',\n",
        "                        type=int, default=1, help='Number of workers')\n",
        "    parser.add_argument('--use-gpu', dest='use_gpu', action='store_true',\n",
        "                        default=False, help='Use GPU')\n",
        "    parser.add_argument('--experiment-name', dest='experiment_name', type=str,\n",
        "                        default='cifar10-torch', help='Experiment name')\n",
        "    parser.add_argument('--logging-dir', dest='logging_dir',\n",
        "                        type=str, default='./logs', help='Logging directory')\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "# Create a simple model\n",
        "class Cifar10Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Cifar10Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def train_epoch(train_loader, model, loss_fn, optimizer, device):\n",
        "    # initiate training\n",
        "    model.train()\n",
        "    train_loss = MeanMetric()\n",
        "    train_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "    # load metrics to device\n",
        "    train_loss.to(device)\n",
        "    train_accuracy.to(device)\n",
        "\n",
        "    # training loop\n",
        "    for batch, (data, target) in enumerate(train_loader):\n",
        "        # move data to device\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # compute error\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        train_loss.update(loss)\n",
        "        train_accuracy.update(output, target)\n",
        "\n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print results\n",
        "        if batch % 100 == 0:\n",
        "            print(f'batch {batch}, loss {loss.item():.4f}')\n",
        "\n",
        "    # compute loss and metrics\n",
        "    train_loss = Tensor.numpy(train_loss.compute(), force=True).item()\n",
        "    train_accuracy = Tensor.numpy(train_accuracy.compute(), force=True).item()\n",
        "\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "\n",
        "def evaluate_epoch(test_loader, model, loss_fn, device):\n",
        "    # initiate evaluation\n",
        "    model.eval()\n",
        "    test_loss = MeanMetric()\n",
        "    test_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "    # load metrics to device\n",
        "    test_loss.to(device)\n",
        "    test_accuracy.to(device)\n",
        "\n",
        "    # evaluation loop\n",
        "    for batch, (data, target) in enumerate(test_loader):\n",
        "        with torch.no_grad():\n",
        "            # move data to device\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # get loss and accuracy\n",
        "            output = model(data)\n",
        "            test_loss.update(loss_fn(output, target))\n",
        "            test_accuracy.update(output, target)\n",
        "\n",
        "    # compute loss and metrics\n",
        "    test_loss = Tensor.numpy(test_loss.compute(), force=True).item()\n",
        "    test_accuracy = Tensor.numpy(test_accuracy.compute(), force=True).item()\n",
        "\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "def train_loop_per_worker(config):\n",
        "    # set configuration\n",
        "    batch_size = config[\"batch_size\"]\n",
        "    epochs = config[\"epochs\"]\n",
        "    learning_rate = config[\"learning_rate\"]\n",
        "\n",
        "    # get device\n",
        "    device = train.torch.get_device() if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "    # read dataset\n",
        "    normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
        "\n",
        "    # Setting url as a fix as mentioned in github issue https://github.com/pytorch/vision/issues/5039#issuecomment-1309696669\n",
        "    datasets.CIFAR10.url=\"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    train_dataset = datasets.CIFAR10(root=\"./train\",\n",
        "                                     transform=transform,\n",
        "                                     train=True, download=True)\n",
        "\n",
        "    test_dataset = datasets.CIFAR10(root=\"./test\",\n",
        "                                    transform=transform,\n",
        "                                    train=False, download=True)\n",
        "\n",
        "    # create data loaders\n",
        "    train_loader = data.DataLoader(train_dataset, batch_size=batch_size)\n",
        "    test_loader = data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "    train_loader = train.torch.prepare_data_loader(train_loader)\n",
        "    test_loader = train.torch.prepare_data_loader(test_loader)\n",
        "\n",
        "    # create model\n",
        "    model = Cifar10Model()\n",
        "    model = train.torch.prepare_model(model)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # train model\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss, train_accuracy = train_epoch(train_loader, model, loss_fn, optimizer, device)\n",
        "        test_loss, test_accuracy = evaluate_epoch(test_loader, model, loss_fn, device)\n",
        "\n",
        "        # report metrics and model checkpoint\n",
        "        train.report(\n",
        "            metrics={\"train_loss\": train_loss, \"train_accuracy\": train_accuracy,\n",
        "                     \"test_loss\": test_loss, \"test_accuracy\": test_accuracy},\n",
        "            checkpoint=TorchCheckpoint.from_state_dict(model.state_dict())\n",
        "        )\n",
        "\n",
        "\n",
        "def main():\n",
        "    # set configuration\n",
        "    args = get_args()\n",
        "    config = vars(args)\n",
        "\n",
        "    # initialize ray session\n",
        "    ray.init()\n",
        "\n",
        "    # train model\n",
        "    train_loop_config = {\"learning_rate\": config['lr'], \"batch_size\": config['batch_size'],\n",
        "                         \"epochs\": config['epochs']}\n",
        "    scaling_config = ScalingConfig(num_workers=config['num_workers'], use_gpu=config['use_gpu'])\n",
        "    run_config = RunConfig(checkpoint_config=CheckpointConfig(num_to_keep=1),\n",
        "                           storage_path=config['logging_dir'],\n",
        "                           name=config['experiment_name'],\n",
        "                           failure_config=FailureConfig(max_failures=5))\n",
        "\n",
        "    trainer = TorchTrainer(\n",
        "        train_loop_per_worker=train_loop_per_worker,\n",
        "        train_loop_config=train_loop_config,\n",
        "        run_config=run_config,\n",
        "        scaling_config=scaling_config\n",
        "    )\n",
        "    result = trainer.fit()\n",
        "    print(f\"Last result: {result.metrics}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\"\"\"\n",
        "\n",
        "with open(src_path / \"task.py\", \"w\") as f:\n",
        "    f.write(training_script)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AOOmNti23qc"
      },
      "source": [
        "### Prepare the requirements file\n",
        "\n",
        "The file `requirements.txt` includes the dependencies your Ray application needs to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83KUQQylbrJR"
      },
      "outputs": [],
      "source": [
        "requirements = \"\"\"\n",
        "importlib_resources==6.1.1\n",
        "etils==1.5.2\n",
        "ray[data]==2.9.3\n",
        "ray[train]==2.9.3\n",
        "ray[tune]==2.9.3\n",
        "torch==2.1.2\n",
        "torchvision==0.16.2\n",
        "torchmetrics==1.2.1\n",
        "setuptools==69.5.1\n",
        "numpy<2\n",
        "\"\"\"\n",
        "\n",
        "with open(tutorial_path / \"requirements.txt\", \"w\") as f:\n",
        "    f.write(requirements)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYcmfEvZ3C1i"
      },
      "source": [
        "### Submit a Ray job using the Ray Jobs API\n",
        "\n",
        "Submit the script to the Ray cluster on Vertex AI using the Ray Jobs API with  the public Ray dashboard address.\n",
        "\n",
        "It's important to highlight that Ray Jobs API is the prefered option if you'd rather submit jobs programmatically. You can also use the Ray on Vertex AI SDK if you prefer an interactive Python development environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPRtGm9IJ09g"
      },
      "source": [
        "Initiate the client to submit the job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FljDHRQ63EP4"
      },
      "outputs": [],
      "source": [
        "client = JobSubmissionClient(address=f\"vertex_ray://{ray_cluster.dashboard_address}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDHIlGlQJ2oi"
      },
      "source": [
        "Submit the job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myMOWdlV3rp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6bd343-d9c0-46ae-caf7-9049f6ed304d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-09-13 12:09:12,633\tINFO dashboard_sdk.py:338 -- Uploading package gcs://_ray_pkg_7f650b2d1ed3deea.zip.\n",
            "2024-09-13 12:09:12,636\tINFO packaging.py:530 -- Creating a file package for local directory '/content/tutorial/src'.\n"
          ]
        }
      ],
      "source": [
        "id = get_id()\n",
        "\n",
        "job_id = client.submit_job(\n",
        "    submission_id=f\"ray-job-{TIMESTAMP}-{id}\",\n",
        "    entrypoint=f\"python3 task.py --experiment-name={EXPERIMENT_NAME} --num-workers=2 --logging-dir={LOGGING_URI}\",\n",
        "    runtime_env={\n",
        "        \"pip\": {\"packages\": str(tutorial_path / \"requirements.txt\")},\n",
        "        \"working_dir\": str(src_path),\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viL5MsRTJ5Df"
      },
      "source": [
        "Check the status of the job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnQfy6VK5pvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc136c67-75a5-445a-f8c9-acabdfc25c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job is running...\n",
            "Job succeeded!\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    job_status = client.get_job_status(job_id)\n",
        "    if job_status == JobStatus.SUCCEEDED:\n",
        "        print(\"Job succeeded!\")\n",
        "        break\n",
        "    else:\n",
        "        if job_status == JobStatus.FAILED:\n",
        "            print(\"Job failed!\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Job is running...\")\n",
        "            time.sleep(60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67FI31SqKFdF"
      },
      "source": [
        "### Check model artifacts\n",
        "\n",
        "When the Ray training job has completed, check the model artifacts in the Cloud Storage location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_JOYhXQKK8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fcda55e-4559-419f-df5a-0077d1a90966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         0  2024-09-13T12:13:34Z  gs://energy-lunar-352813-001/logs/torch_on_rov/\n",
            "         0  2024-09-13T12:13:34Z  gs://energy-lunar-352813-001/logs/torch_on_rov/.validate_storage_marker\n",
            "      7374  2024-09-13T12:25:32Z  gs://energy-lunar-352813-001/logs/torch_on_rov/basic-variant-state-2024-09-13_12-13-35.json\n",
            "     18766  2024-09-13T12:25:32Z  gs://energy-lunar-352813-001/logs/torch_on_rov/experiment_state-2024-09-13_12-13-35.json\n",
            "      5246  2024-09-13T12:25:32Z  gs://energy-lunar-352813-001/logs/torch_on_rov/trainer.pkl\n",
            "      1414  2024-09-13T12:25:32Z  gs://energy-lunar-352813-001/logs/torch_on_rov/tuner.pkl\n",
            "                                 gs://energy-lunar-352813-001/logs/torch_on_rov/TorchTrainer_99503_00000_0_2024-09-13_12-13-35/\n",
            "TOTAL: 6 objects, 32800 bytes (32.03 KiB)\n"
          ]
        }
      ],
      "source": [
        "! gsutil ls -l {TRAINING_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKUOXlN-MBaU"
      },
      "source": [
        "## Serving a PyTorch model\n",
        "\n",
        "You can serve a PyTorch model on Vertex AI using TorchServe as follows:\n",
        "\n",
        "1. Download Ray training checkpoints.\n",
        "2. Get PyTorch model from the Ray TorchCheckpoint.\n",
        "3. Package the trained model artifacts including the model artifact, the model module and the custom handler by creating an archive file using the Torch Model Archiver tool.\n",
        "4. Register model in Vertex AI Model Registry.\n",
        "5. Deploy model to Vertex AI endpoint for predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN5YQ60PXbYq"
      },
      "source": [
        "### Download Ray training checkpoints\n",
        "\n",
        "Download all resulting checkpoints from Ray training job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBf0_agLhrLV"
      },
      "outputs": [],
      "source": [
        "! gsutil -q cp -r {TRAINING_URI} {DELIVERABLES_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VavpxaY1hlSN"
      },
      "source": [
        "### Get the best training checkpoint\n",
        "\n",
        "Use the `ExperimentAnalysis` to retrive the best checkpoint according to relevant metrics and mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUBEKpK1gVx9"
      },
      "outputs": [],
      "source": [
        "experiment_analysis = ExperimentAnalysis(TRAINING_PATH)\n",
        "log_path = experiment_analysis.get_best_trial(metric=\"test_accuracy\", mode=\"max\")\n",
        "best_checkpoint = experiment_analysis.get_best_checkpoint(\n",
        "    log_path, metric=\"test_accuracy\", mode=\"max\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf2YPC5nlzjL"
      },
      "source": [
        "### Get PyTorch Model from Ray TorchCheckpoint\n",
        "\n",
        "Convert a TorchCheckpoint to Pytorch Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78577f79de54"
      },
      "outputs": [],
      "source": [
        "class Cifar10Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_definition = Cifar10Model()\n",
        "torch_model = ray_torch.get_pytorch_model_from(best_checkpoint, model=model_definition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY5AV09xm0dl"
      },
      "source": [
        "### Build PyTorch model archive (.mar) file\n",
        "\n",
        "TorchServe lets you to serve the Torch model by packaging all model artifacts into a single model archive file. In this case, the following information is required to create a standalone model archive:\n",
        "\n",
        "1. Serialized file\n",
        "2. Model file\n",
        "3. Handler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvfiYnrZ63iN"
      },
      "source": [
        "#### Save the model\n",
        "\n",
        "The `model.pt` contains the model state_dict.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLR_MZS_tXuq"
      },
      "outputs": [],
      "source": [
        "torch.save(torch_model.state_dict(), build_path / \"model.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl-xT_zDmOvg"
      },
      "source": [
        "#### Create the model module\n",
        "\n",
        "The `model.py` file should contain the model architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT9Szm-LA8Uh"
      },
      "outputs": [],
      "source": [
        "model_script = \"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Cifar10Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Cifar10Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\"\"\"\n",
        "\n",
        "with open(build_path / \"model.py\", \"w\") as model_file:\n",
        "    model_file.write(model_script)\n",
        "model_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5Jc76AmBP-C"
      },
      "source": [
        "#### Create the custom_handler module\n",
        "\n",
        "The `custom_handler.py` file uses the TorchServe's inbuilt `image_classifier` handler name to handle custom TorchServe inference logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDpXiVHnBPJ-"
      },
      "outputs": [],
      "source": [
        "custom_handler_script = '''\n",
        "# Based on https://github.com/pytorch/serve/blob/master/examples/image_classifier/mnist/mnist_handler.py\n",
        "\n",
        "from torchvision import transforms\n",
        "from ts.torch_handler.image_classifier import ImageClassifier\n",
        "from torch.profiler import ProfilerActivity\n",
        "\n",
        "\n",
        "class Cifar10Classifier(ImageClassifier):\n",
        "    \"\"\"\n",
        "    Cifar10Classifier handler class. This handler extends ImageClassifier class\n",
        "    \"\"\"\n",
        "\n",
        "    label_names = [\n",
        "        \"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "    ]\n",
        "\n",
        "    image_processing = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Cifar10Classifier, self).__init__()\n",
        "        self.profiler_args = {\n",
        "            \"activities\": [ProfilerActivity.CPU],\n",
        "            \"record_shapes\": True,\n",
        "        }\n",
        "\n",
        "    def postprocess(self, data):\n",
        "        \"\"\"\n",
        "        Post-process function to convert the predicted class id to label\n",
        "        \"\"\"\n",
        "        predictions = data.argmax(1).tolist()\n",
        "        return [self.label_names[pred] for pred in predictions]\n",
        "\n",
        "'''\n",
        "\n",
        "with open(build_path / \"custom_handler.py\", \"w\") as custom_handler_file:\n",
        "    custom_handler_file.write(custom_handler_script)\n",
        "custom_handler_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2YY73mBByKt"
      },
      "source": [
        "#### Package the model artifacts in a model archive file\n",
        "\n",
        "Use the Torch Model Archiver tool to create a model archive file (.mar).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVzPb0oxETee"
      },
      "outputs": [],
      "source": [
        "build_script = \"\"\"\n",
        "torch-model-archiver -f --model-name cifar10 \\\n",
        "    --version 1.0  \\\n",
        "    --model-file model.py \\\n",
        "    --serialized-file model.pt \\\n",
        "    --handler custom_handler.py \\\n",
        "    --export-path .\n",
        "\"\"\"\n",
        "\n",
        "with open(build_path / \"build.sh\", \"w\") as build_file:\n",
        "    build_file.write(build_script)\n",
        "build_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d09sIVOaCFQE"
      },
      "outputs": [],
      "source": [
        "! cd {str(build_path)} && chmod +x ./build.sh && ./build.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zljbquGFtHP"
      },
      "source": [
        "#### Upload mar to bucket\n",
        "\n",
        "Store the .mar file to Cloud bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPejvg6uFzBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f577c16b-e5e5-42cd-82b6-cb1d3dff435d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file:///content/tutorial/build/cifar10.mar [Content-Type=application/octet-stream]...\n",
            "/ [1 files][243.1 KiB/243.1 KiB]                                                \n",
            "Operation completed over 1 objects/243.1 KiB.                                    \n"
          ]
        }
      ],
      "source": [
        "!gsutil cp {str(build_path)}/cifar10.mar {BUILD_URI}/model.mar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi3I6JotDw3k"
      },
      "source": [
        "### Register model in Vertex AI Model Registry\n",
        "\n",
        "Register the model as a Model resource in Vertex AI Model Registry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kyOITop38H7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c6b36d-c427-45df-8f2c-c37deddbbd6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:Creating Model\n",
            "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/892203813305/locations/us-central1/models/3450242199193649152/operations/7499299493393727488\n",
            "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/892203813305/locations/us-central1/models/3450242199193649152@1\n",
            "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
            "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/892203813305/locations/us-central1/models/3450242199193649152@1')\n"
          ]
        }
      ],
      "source": [
        "registered_model = vertex_ai.Model.upload(\n",
        "    display_name=MODEL_NAME,\n",
        "    serving_container_image_uri=DEPLOY_IMAGE_URI,\n",
        "    artifact_uri=BUILD_URI,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko3IfZgbEG1J"
      },
      "source": [
        "### Deploy model for predictions\n",
        "\n",
        "Create a Vertex AI endpoint and deploy the registered model for predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSukFOf04IMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d538bf8-77ee-49c1-bbfb-298e8d6bccc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
            "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/892203813305/locations/us-central1/endpoints/2055120273220304896/operations/2425994513160863744\n",
            "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/892203813305/locations/us-central1/endpoints/2055120273220304896\n",
            "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
            "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/892203813305/locations/us-central1/endpoints/2055120273220304896')\n",
            "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/892203813305/locations/us-central1/endpoints/2055120273220304896\n",
            "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/892203813305/locations/us-central1/endpoints/2055120273220304896/operations/9050789565022863360\n",
            "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/892203813305/locations/us-central1/endpoints/2055120273220304896\n"
          ]
        }
      ],
      "source": [
        "endpoint = registered_model.deploy(\n",
        "    deployed_model_display_name=MODEL_NAME,\n",
        "    machine_type=DEPLOY_COMPUTE,\n",
        "    accelerator_type=None,\n",
        "    accelerator_count=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzHtXzv0E2sg"
      },
      "source": [
        "## Make online predictions\n",
        "\n",
        "Sample an image from the CIFAR10 dataset for getting online predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdRjvCOX4hVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d82e66-8562-4ca5-8501-393d81115de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/tutorial/tests/data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 45713620.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/tutorial/tests/data/cifar-10-python.tar.gz to /content/tutorial/tests/data\n"
          ]
        }
      ],
      "source": [
        "# Setting url as a fix as mentioned in github issue https://github.com/pytorch/vision/issues/5039#issuecomment-1309696669\n",
        "datasets.CIFAR10.url = \"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root=tests_path / \"data\",\n",
        "    transform=transforms.ToTensor(),\n",
        "    train=False,\n",
        "    download=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFuZC39WbIJL"
      },
      "source": [
        "Visualize the sampled image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDWLHAuPWo_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "2fe67c42-c467-4dd8-a1d7-6aa62c8e2a72"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "pil_image = plot_image_sample(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeuZLWpRbLyT"
      },
      "source": [
        "Run a prediction request and get the predicted class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPqDTh184fM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8ed597-f86f-44c0-e0eb-7f8042abbcf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: plane\n"
          ]
        }
      ],
      "source": [
        "predictions = predict_from_image(pil_image, endpoint)\n",
        "\n",
        "for pred in predictions:\n",
        "    print(\"Predicted class:\", pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "7083df4f-bbb1-4758-8178-8267f9fe8162"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shutil' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-20e8f9b9e80d>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Delete tutorial folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelete_tutorial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtutorial_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Delete Cloud Storage objects that were created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shutil' is not defined"
          ]
        }
      ],
      "source": [
        "delete_endpoint = False\n",
        "delete_model = False\n",
        "delete_ray_cluster = False\n",
        "delete_bucket = True\n",
        "delete_tutorial = True\n",
        "\n",
        "# Delete endpoint resource\n",
        "if delete_endpoint:\n",
        "    endpoint.delete(force=True)\n",
        "\n",
        "# Delete model resource\n",
        "if delete_model:\n",
        "    registered_model.delete()\n",
        "\n",
        "# Delete ray on vertex cluster\n",
        "if delete_ray_cluster:\n",
        "    vertex_ray.delete_ray_cluster(ray_cluster.cluster_resource_name)\n",
        "\n",
        "# Delete tutorial folder\n",
        "if delete_tutorial:\n",
        "    shutil.rmtree(tutorial_path)\n",
        "\n",
        "# Delete Cloud Storage objects that were created\n",
        "if delete_bucket:\n",
        "    ! gsutil -q -m rm -r $BUCKET_URI"
      ]
    }
  ]
}